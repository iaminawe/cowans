#!/usr/bin/env python3
"""
Shopify Complete Collections Exporter

This script downloads comprehensive collection data from a Shopify store,
including all metadata needed to recreate collections identically on another site.

Usage:
    python export_complete_collections.py --shop-url store.myshopify.com --access-token TOKEN
"""

import os
import sys
import csv
import json
import argparse
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime

try:
    from .shopify_base import ShopifyAPIBase
except ImportError:
    from shopify_base import ShopifyAPIBase

# Comprehensive collections query with ALL available fields
COMPLETE_COLLECTIONS_QUERY = """
query getCompleteCollections($first: Int!, $after: String) {
  collections(first: $first, after: $after) {
    edges {
      node {
        id
        handle
        title
        description
        descriptionHtml
        updatedAt
        image {
          url
          altText
        }
        
        seo {
          title
          description
        }
        
        sortOrder
        templateSuffix
        
        products(first: 250) {
          edges {
            node {
              id
              handle
              title
            }
          }
          pageInfo {
            hasNextPage
            endCursor
          }
        }
        
        productsCount {
          count
        }
      }
      cursor
    }
    pageInfo {
      hasNextPage
      endCursor
    }
  }
}
"""

# Query for custom collections (manual collections)
CUSTOM_COLLECTIONS_QUERY = """
query getCustomCollections($first: Int!, $after: String) {
  collections(first: $first, after: $after, query: "collection_type:custom") {
    edges {
      node {
        id
        handle
        title
        collectionType: __typename
      }
    }
  }
}
"""

# Query for smart collections (automated collections)
SMART_COLLECTIONS_QUERY = """
query getSmartCollections($first: Int!, $after: String) {
  collections(first: $first, after: $after, query: "collection_type:smart") {
    edges {
      node {
        id
        handle
        title
        collectionType: __typename
      }
    }
  }
}
"""

class ShopifyCompleteCollectionExporter(ShopifyAPIBase):
    """Exports complete Shopify collection data for recreation."""
    
    def __init__(self, shop_url: str, access_token: str, debug: bool = False):
        """Initialize the exporter."""
        super().__init__(shop_url, access_token, debug)
        self.logger = logging.getLogger(__name__)
        
    def export_collections(self, output_dir: str = "collection_export") -> None:
        """Export all collection data to multiple files."""
        print(f"üöÄ Starting complete collection export to: {output_dir}/")
        
        # Create output directory
        os.makedirs(output_dir, exist_ok=True)
        
        # Export different aspects of collections
        self._export_collection_metadata(os.path.join(output_dir, "collections_metadata.csv"))
        self._export_collection_rules(os.path.join(output_dir, "collections_rules.csv"))
        self._export_collection_products(os.path.join(output_dir, "collections_products.csv"))
        self._export_collection_seo(os.path.join(output_dir, "collections_seo.csv"))
        self._export_collection_images(os.path.join(output_dir, "collections_images.csv"))
        
        # Also export as JSON for complete data preservation
        self._export_collections_json(os.path.join(output_dir, "collections_complete.json"))
        
        print(f"\n‚úÖ Export completed successfully!")
        print(f"üìÅ Files saved in: {output_dir}/")
        
    def _export_collection_metadata(self, output_file: str) -> None:
        """Export core collection metadata."""
        print("\nüìä Exporting collection metadata...")
        
        fieldnames = [
            'collection_id', 'collection_handle', 'collection_title',
            'collection_type', 'description', 'description_html',
            'sort_order', 'template_suffix', 'products_count',
            'published', 'updated_at', 'disjunctive_rules'
        ]
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            collections = self._fetch_all_collections()
            
            for collection in collections:
                # Determine collection type
                has_rules = collection.get('ruleSet') is not None
                collection_type = 'smart' if has_rules else 'custom'
                
                # Get disjunctive setting
                disjunctive = False
                if has_rules:
                    disjunctive = collection['ruleSet'].get('appliedDisjunctively', False)
                
                writer.writerow({
                    'collection_id': collection.get('id'),
                    'collection_handle': collection.get('handle'),
                    'collection_title': collection.get('title'),
                    'collection_type': collection_type,
                    'description': collection.get('description', ''),
                    'description_html': collection.get('descriptionHtml', ''),
                    'sort_order': collection.get('sortOrder', ''),
                    'template_suffix': collection.get('templateSuffix', ''),
                    'products_count': collection.get('productsCount', {}).get('count', 0),
                    'published': collection.get('publishedOnCurrentPublication', True),
                    'updated_at': collection.get('updatedAt'),
                    'disjunctive_rules': 'any' if disjunctive else 'all'
                })
        
        print(f"   ‚úì Exported metadata for {len(collections)} collections")
        
    def _export_collection_rules(self, output_file: str) -> None:
        """Export smart collection rules."""
        print("\nüîß Exporting collection rules...")
        
        fieldnames = [
            'collection_handle', 'collection_title', 'rule_index',
            'column', 'relation', 'condition', 'applied_disjunctively'
        ]
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            collections = self._fetch_all_collections()
            rules_count = 0
            
            for collection in collections:
                rule_set = collection.get('ruleSet')
                if rule_set and rule_set.get('rules'):
                    for idx, rule in enumerate(rule_set['rules']):
                        writer.writerow({
                            'collection_handle': collection.get('handle'),
                            'collection_title': collection.get('title'),
                            'rule_index': idx + 1,
                            'column': rule.get('column'),
                            'relation': rule.get('relation'),
                            'condition': rule.get('condition'),
                            'applied_disjunctively': rule_set.get('appliedDisjunctively', False)
                        })
                        rules_count += 1
        
        print(f"   ‚úì Exported {rules_count} rules from smart collections")
        
    def _export_collection_products(self, output_file: str) -> None:
        """Export collection-product relationships."""
        print("\nüì¶ Exporting collection products...")
        
        fieldnames = [
            'collection_handle', 'collection_title', 'collection_type',
            'product_id', 'product_handle', 'product_title', 'position'
        ]
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            collections = self._fetch_all_collections()
            total_relationships = 0
            
            for collection in collections:
                # Determine collection type
                collection_type = 'smart' if collection.get('ruleSet') else 'custom'
                
                # Get all products in collection (with pagination if needed)
                products = self._fetch_all_collection_products(collection)
                
                for position, product in enumerate(products, 1):
                    writer.writerow({
                        'collection_handle': collection.get('handle'),
                        'collection_title': collection.get('title'),
                        'collection_type': collection_type,
                        'product_id': product.get('id'),
                        'product_handle': product.get('handle'),
                        'product_title': product.get('title'),
                        'position': position
                    })
                    total_relationships += 1
        
        print(f"   ‚úì Exported {total_relationships} product-collection relationships")
        
    def _export_collection_seo(self, output_file: str) -> None:
        """Export collection SEO data."""
        print("\nüîç Exporting collection SEO data...")
        
        fieldnames = [
            'collection_handle', 'collection_title',
            'seo_title', 'seo_description', 'url_handle'
        ]
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            collections = self._fetch_all_collections()
            
            for collection in collections:
                seo = collection.get('seo', {})
                writer.writerow({
                    'collection_handle': collection.get('handle'),
                    'collection_title': collection.get('title'),
                    'seo_title': seo.get('title', ''),
                    'seo_description': seo.get('description', ''),
                    'url_handle': collection.get('handle')
                })
        
        print(f"   ‚úì Exported SEO data for {len(collections)} collections")
        
    def _export_collection_images(self, output_file: str) -> None:
        """Export collection image data."""
        print("\nüñºÔ∏è  Exporting collection images...")
        
        fieldnames = [
            'collection_handle', 'collection_title',
            'image_url', 'image_alt_text', 'image_width', 'image_height'
        ]
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            collections = self._fetch_all_collections()
            images_count = 0
            
            for collection in collections:
                image = collection.get('image', {})
                if image:
                    writer.writerow({
                        'collection_handle': collection.get('handle'),
                        'collection_title': collection.get('title'),
                        'image_url': image.get('url', ''),
                        'image_alt_text': image.get('altText', ''),
                        'image_width': image.get('width', ''),
                        'image_height': image.get('height', '')
                    })
                    images_count += 1
        
        print(f"   ‚úì Exported {images_count} collection images")
        
    def _export_collections_json(self, output_file: str) -> None:
        """Export complete collection data as JSON."""
        print("\nüíæ Exporting complete collection data as JSON...")
        
        collections = self._fetch_all_collections()
        
        # Clean up GraphQL specific fields
        for collection in collections:
            if 'products' in collection:
                collection['products'] = [
                    edge['node'] for edge in collection['products'].get('edges', [])
                ]
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(collections, f, indent=2, ensure_ascii=False)
        
        print(f"   ‚úì Exported complete data for {len(collections)} collections")
        
    def _fetch_all_collections(self) -> List[Dict[str, Any]]:
        """Fetch all collections with pagination."""
        collections = []
        has_next_page = True
        cursor = None
        
        while has_next_page:
            variables = {'first': 50}
            if cursor:
                variables['after'] = cursor
                
            result = self.execute_graphql(COMPLETE_COLLECTIONS_QUERY, variables)
            
            if 'errors' in result:
                raise Exception(f"GraphQL errors: {result['errors']}")
                
            collections_data = result.get('data', {}).get('collections', {})
            edges = collections_data.get('edges', [])
            
            for edge in edges:
                collections.append(edge['node'])
                
            page_info = collections_data.get('pageInfo', {})
            has_next_page = page_info.get('hasNextPage', False)
            cursor = page_info.get('endCursor')
            
            print(f"   Fetched {len(collections)} collections so far...")
            
        return collections
        
    def _fetch_all_collection_products(self, collection: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Fetch all products for a collection (handling pagination)."""
        products = []
        
        # Get initial products from collection query
        products_data = collection.get('products', {})
        edges = products_data.get('edges', [])
        
        for edge in edges:
            products.append(edge['node'])
            
        # Check if we need to paginate for more products
        page_info = products_data.get('pageInfo', {})
        if page_info.get('hasNextPage', False):
            # For simplicity, we'll just note this - full implementation would paginate
            print(f"   ‚ö†Ô∏è  Collection '{collection.get('handle')}' has more than 250 products")
            
        return products


def main():
    """Main function."""
    parser = argparse.ArgumentParser(
        description='Export complete Shopify collection data for recreation'
    )
    parser.add_argument('--shop-url', required=True, help='Shopify store URL')
    parser.add_argument('--access-token', required=True, help='Shopify access token')
    parser.add_argument('--output-dir', default='collection_export', 
                       help='Output directory (default: collection_export)')
    parser.add_argument('--debug', action='store_true', help='Enable debug logging')
    
    args = parser.parse_args()
    
    # Configure logging
    logging.basicConfig(
        level=logging.DEBUG if args.debug else logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        # Create exporter and run export
        exporter = ShopifyCompleteCollectionExporter(
            shop_url=args.shop_url,
            access_token=args.access_token,
            debug=args.debug
        )
        
        exporter.export_collections(args.output_dir)
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Export interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå Error: {str(e)}")
        if args.debug:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()